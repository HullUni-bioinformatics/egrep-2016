{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dave made a list of taxonomic groups that should be included in the reference database:\n",
    "\n",
    "1. Hexapoda 1.4 million seqs\n",
    "2. Arachnida 76,572 seqs\n",
    "3. Myriapoda  2,124 seqs\n",
    "5. Mollusca (some, complete coverage not required)\n",
    "6. Nematomorpha (just to see)\n",
    "6. Oniscidea (woodlice)\n",
    "7. Fungi; a few ascomycetes and basidomycetes\n",
    "8. Vertebrate; a few diverse bird and mammal maybe\n",
    "\n",
    "To make the download easier we are going to break down 'Hexapoda' into smaller groups:\n",
    "\n",
    "    collembola\n",
    "    diplura\n",
    "    protura\n",
    "    insecta\n",
    "        Ephemeroptera\n",
    "        Odonata\n",
    "        Embioptera\n",
    "        Endopterygota\n",
    "        Amphiesmenoptera\n",
    "        Coleoptera\n",
    "        Diptera\n",
    "        Hymenoptera\n",
    "        Mecoptera\n",
    "        Neuropterida\n",
    "        Siphonaptera\n",
    "        Orthopteroidea\n",
    "        Paraneoptera\n",
    "        Plecoptera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write everything to a text file and let a script do the work - process the file line by line downloading all available COI sequences for the taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hexapoda_to_download.txt\n"
     ]
    }
   ],
   "source": [
    "%%file hexapoda_to_download.txt\n",
    "collembola\n",
    "diplura\n",
    "protura\n",
    "Ephemeroptera\n",
    "Odonata\n",
    "Embioptera\n",
    "Amphiesmenoptera\n",
    "Coleoptera\n",
    "Diptera\n",
    "Hymenoptera\n",
    "Mecoptera\n",
    "Neuropterida\n",
    "Siphonaptera\n",
    "Orthopteroidea\n",
    "Paraneoptera\n",
    "Plecoptera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: fetch_from_db.py [-h] [-t <FILE>] [-a <FILE>] [-m <string>] [-G] [-B]\r\n",
      "                        [--no-download] [--geo <string>] [-o <string>]\r\n",
      "                        [-@ <email-address>] [--version]\r\n",
      "\r\n",
      "Fetch all available DNA sequences for a list of taxa and a given marker gene\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -t <FILE>, --taxlist <FILE>\r\n",
      "                        text file containing list of taxa to search for on\r\n",
      "                        Genbank\r\n",
      "  -a <FILE>, --accessionlist <FILE>\r\n",
      "                        text file containing list of accessions to fetch from\r\n",
      "                        Genbank\r\n",
      "  -m <string>, --marker <string>\r\n",
      "                        name of gene to be searched for (put in \"\" if the\r\n",
      "                        search term consists of more than one word\r\n",
      "  -G, --Genbank         search Genbank\r\n",
      "  -B, --BOLD            search BOLD\r\n",
      "  --no-download         search Genbank and just return the number of records\r\n",
      "                        found for list of taxa\r\n",
      "  --geo <string>        limit BOLD search to countries/continents. for more\r\n",
      "                        than one write as follows: \"Austria|UK\"\r\n",
      "  -o <string>, --out <string>\r\n",
      "                        prefix for output files (default=\"out\")\r\n",
      "  -@ <email-address>, --email <email-address>\r\n",
      "                        provide your email address for identification to NCBI\r\n",
      "  --version             show program's version number and exit\r\n"
     ]
    }
   ],
   "source": [
    "!fetch_from_db.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all available COI sequences for the taxonomic groups specified in the file, one by one. This will download >1.5 M sequences from Genbank so it takes a few hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for t in $(cat hexapoda_to_download.txt)\n",
    "do\n",
    "    echo -e \"\\n### Downloading: $t ###\\n\"\n",
    "    echo $t > current.txt\n",
    "    fetch_from_db.py -G -m COI -o $t -t current.txt \n",
    "    rm current.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now lets download stuff for the remaining groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting others_to_downlaod.txt\n"
     ]
    }
   ],
   "source": [
    "%%file others_to_downlaod.txt\n",
    "Arachnida\n",
    "Myriapoda\n",
    "Mollusca\n",
    "Nematomorpha\n",
    "Oniscidea\n",
    "Vertebrata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vertebrata download broke a few times and I had to resume it by restarting the script and point it to the file `Vertebrate.accessions.txt` (using the option`-a`) that is produced during the download and that contains the accessions of the records that have not yet been downloaded. Vertebrates are of minor important in this dataset so you can also just skip them alltogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for t in $(cat others_to_downlaod.txt)\n",
    "do\n",
    "    echo -e \"\\n### Downloading: $t ###\\n\"\n",
    "    echo $t > current.txt\n",
    "    fetch_from_db.py -G -m COI -o $t -t current.txt \n",
    "    rm current.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Fungi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Fungi_to_download.txt\n"
     ]
    }
   ],
   "source": [
    "%%file Fungi_to_download.txt\n",
    "Cercospora\n",
    "Didymella\n",
    "Calonectria\n",
    "Fusarium\n",
    "Melampsora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!fetch_from_db.py -G -m COI -o Fungi -t Fungi_to_download.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting postives.txt\n"
     ]
    }
   ],
   "source": [
    "%%file postives.txt\n",
    "Astatotilapia calliptera\n",
    "Triops cancriformis\n",
    "Comaster audax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!fetch_from_db.py -G -m COI -o positives -t postives.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some weird records that hamper the correct taxonomic assignment for _Harmonia axyridis_ should be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AJ312060.1\r\n",
      "AJ313070.1\r\n",
      "AY533712.1\r\n",
      "AY533715.1\r\n",
      "AY533722.1\r\n",
      "AY533732.1\r\n",
      "AY533736.1\r\n",
      "AY533742.1\r\n",
      "AY533751.1\r\n",
      "AY533753.1\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 to_exclude.accessions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh=open('to_exclude.accessions.txt','r')\n",
    "\n",
    "to_ex = []\n",
    "\n",
    "for l in fh:\n",
    "    to_ex.append(l.strip())\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format reference database for use with Kraken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def gb_to_blast(db_in_gb, db_for_blast, to_exclude=[], minlength=200, maxlength=10000, v=0):\n",
    "\n",
    "    from Bio import SeqIO\n",
    "\n",
    "    Seqs_new = []\n",
    "    out = open(db_for_blast,'w')\n",
    "    ex = []\n",
    "    total = 0\n",
    "    \n",
    "    if to_exclude:\n",
    "        ex = list(set(to_exclude))\n",
    "    \n",
    "    for f in db_in_gb:\n",
    "        print \"processing %s .. \" %f,\n",
    "        Seqs = SeqIO.parse(open(f,'r'), 'genbank')\n",
    "        count = 0\n",
    "        ok = 0\n",
    "        skipped = 0\n",
    "        excluded = 0\n",
    "        \n",
    "        for r in Seqs:\n",
    "            count+=1\n",
    "            if r.id in ex or len(r.seq) < minlength or len(r.seq) > maxlength:\n",
    "                if v:\n",
    "                    print \"\\nexcluding %s\" %r.id\n",
    "                excluded+=1\n",
    "                continue\n",
    "            taxid = ''\n",
    "            source=r.features[0]\n",
    "            for t in source.qualifiers['db_xref']:\n",
    "                if 'taxon' in t:\n",
    "                    taxid = t.split(\":\")[1]\n",
    "        \n",
    "            if taxid:    \n",
    "                organism = source.qualifiers['organism'][0].replace(' ','_')\n",
    "                r.description = \"%s|%s|%s\" %(r.id,taxid,organism)\n",
    "                r.id = r.description\n",
    "                Seqs_new.append(r)\n",
    "                ok+=1\n",
    "            else:\n",
    "                if v:\n",
    "                    print \"\\nWARNING: No taxid detected for record: %s - skipping\" %r.id\n",
    "                skipped+=1\n",
    "                continue\n",
    "\n",
    "            if len(Seqs_new) == 1000:\n",
    "            \n",
    "                SeqIO.write(Seqs_new, out, 'fasta')\n",
    "                Seqs_new = []\n",
    "\n",
    "        SeqIO.write(Seqs_new, out, 'fasta')\n",
    "    \n",
    "        print \" converted %i / %i sequences (%i excluded, %i skipped).\\n\" %(ok,count,excluded,skipped)\n",
    "        total+=ok\n",
    "    out.close()\n",
    "    \n",
    "    print \"Done - Converted a total of %i records!\" %total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing Amphiesmenoptera.gb ..   converted 400056 / 421311 sequences (21255 excluded, 0 skipped).\n",
      "\n",
      "processing Arachnida.gb ..   converted 80859 / 87682 sequences (6823 excluded, 0 skipped).\n",
      "\n",
      "processing Coleoptera.gb ..   converted 127019 / 136607 sequences (9588 excluded, 0 skipped).\n",
      "\n",
      "processing Diptera.gb ..   converted 589433 / 600506 sequences (11073 excluded, 0 skipped).\n",
      "\n",
      "processing Embioptera.gb ..   converted 78 / 105 sequences (27 excluded, 0 skipped).\n",
      "\n",
      "processing Ephemeroptera.gb ..   converted 10900 / 11230 sequences (330 excluded, 0 skipped).\n",
      "\n",
      "processing Fungi.gb ..   converted 110 / 163 sequences (53 excluded, 0 skipped).\n",
      "\n",
      "processing Hymenoptera.gb ..   converted 180363 / 192517 sequences (12154 excluded, 0 skipped).\n",
      "\n",
      "processing Mecoptera.gb ..   converted 371 / 378 sequences (7 excluded, 0 skipped).\n",
      "\n",
      "processing Mollusca.gb ..   converted 87255 / 92813 sequences (5558 excluded, 0 skipped).\n",
      "\n",
      "processing Myriapoda.gb ..   converted 2259 / 2328 sequences (69 excluded, 0 skipped).\n",
      "\n",
      "processing Nematomorpha.gb ..   converted 112 / 112 sequences (0 excluded, 0 skipped).\n",
      "\n",
      "processing Neuropterida.gb ..   converted 3049 / 3315 sequences (266 excluded, 0 skipped).\n",
      "\n",
      "processing Odonata.gb ..   converted 5774 / 6568 sequences (794 excluded, 0 skipped).\n",
      "\n",
      "processing Oniscidea.gb ..   converted 1812 / 1888 sequences (76 excluded, 0 skipped).\n",
      "\n",
      "processing Orthopteroidea.gb ..   converted 11982 / 14793 sequences (2811 excluded, 0 skipped).\n",
      "\n",
      "processing Paraneoptera.gb ..   converted 101933 / 107912 sequences (5979 excluded, 0 skipped).\n",
      "\n",
      "processing Plecoptera.gb ..   converted 4072 / 4499 sequences (427 excluded, 0 skipped).\n",
      "\n",
      "processing Siphonaptera.gb ..   converted 234 / 430 sequences (196 excluded, 0 skipped).\n",
      "\n",
      "processing Vertebrata.temp.gb ..   converted 165596 / 217000 sequences (51404 excluded, 0 skipped).\n",
      "\n",
      "processing collembola.gb ..   converted 24115 / 24464 sequences (349 excluded, 0 skipped).\n",
      "\n",
      "processing diplura.gb ..   converted 34 / 48 sequences (14 excluded, 0 skipped).\n",
      "\n",
      "processing positives.gb ..   converted 103 / 111 sequences (8 excluded, 0 skipped).\n",
      "\n",
      "processing protura.gb ..   converted 18 / 24 sequences (6 excluded, 0 skipped).\n",
      "\n",
      "Done - Converted a total of 1797537 records!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "datadir = './'\n",
    "####################\n",
    "gbs = []\n",
    "files = os.listdir(datadir)\n",
    "for f in sorted(files):\n",
    "    if f.endswith('gb'):\n",
    "        gbs.append(f)\n",
    "        \n",
    "gb_to_blast(db_in_gb=gbs, db_for_blast='all.blast.fasta', to_exclude=to_ex, minlength=400, maxlength=1000, v=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gb_to_kraken(db_in_gb, db_for_kraken, to_exclude=[], minlength=200, maxlength=10000, v=0):\n",
    "\n",
    "    from Bio import SeqIO\n",
    "\n",
    "    Seqs_new = []\n",
    "    out = open(db_for_kraken,'w')\n",
    "    \n",
    "    total = 0\n",
    "    ex = []\n",
    "    \n",
    "    if to_exclude:\n",
    "        ex = list(set(to_exclude))\n",
    "    \n",
    "    for f in db_in_gb:\n",
    "        print \"processing %s .. \" %f,\n",
    "        Seqs = SeqIO.parse(open(f,'r'), 'genbank')\n",
    "        count = 0\n",
    "        ok = 0\n",
    "        skipped = 0\n",
    "        excluded = 0\n",
    "        \n",
    "        for r in Seqs:\n",
    "            count+=1\n",
    "            if r.id in ex or len(r.seq) < minlength or len(r.seq) > maxlength:\n",
    "                if v:\n",
    "                    print \"\\nexcluding %s\" %r.id\n",
    "                excluded+=1\n",
    "                continue\n",
    "            taxid = ''\n",
    "            source=r.features[0]\n",
    "            for t in source.qualifiers['db_xref']:\n",
    "                if 'taxon' in t:\n",
    "                    taxid = t.split(\":\")[1]\n",
    "        \n",
    "            if taxid:        \n",
    "                r.id = \"%s|kraken:taxid|%s\" %(r.id,taxid)\n",
    "                r.description = r.id\n",
    "                Seqs_new.append(r)\n",
    "                ok+=1\n",
    "            else:\n",
    "                if v:\n",
    "                    print \"\\nWARNING: No taxid detected for record: %s - skipping\" %r.id\n",
    "                skipped+=1\n",
    "                continue\n",
    "\n",
    "            if len(Seqs_new) == 1000:\n",
    "            \n",
    "                SeqIO.write(Seqs_new, out, 'fasta')\n",
    "                Seqs_new = []\n",
    "\n",
    "        SeqIO.write(Seqs_new, out, 'fasta')\n",
    "    \n",
    "        print \" converted %i / %i sequences (%i excluded, %i skipped).\\n\" %(ok,count,excluded,skipped)\n",
    "        total+=ok\n",
    "    out.close()\n",
    "    \n",
    "    print \"Done - Converted a total of %i records!\" %total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing Amphiesmenoptera.gb ..   converted 400056 / 421311 sequences (21255 excluded, 0 skipped).\n",
      "\n",
      "processing Arachnida.gb ..   converted 80859 / 87682 sequences (6823 excluded, 0 skipped).\n",
      "\n",
      "processing Coleoptera.gb ..   converted 127019 / 136607 sequences (9588 excluded, 0 skipped).\n",
      "\n",
      "processing Diptera.gb ..   converted 589433 / 600506 sequences (11073 excluded, 0 skipped).\n",
      "\n",
      "processing Embioptera.gb ..   converted 78 / 105 sequences (27 excluded, 0 skipped).\n",
      "\n",
      "processing Ephemeroptera.gb ..   converted 10900 / 11230 sequences (330 excluded, 0 skipped).\n",
      "\n",
      "processing Fungi.gb ..   converted 110 / 163 sequences (53 excluded, 0 skipped).\n",
      "\n",
      "processing Hymenoptera.gb ..   converted 180363 / 192517 sequences (12154 excluded, 0 skipped).\n",
      "\n",
      "processing Mecoptera.gb ..   converted 371 / 378 sequences (7 excluded, 0 skipped).\n",
      "\n",
      "processing Mollusca.gb ..   converted 87255 / 92813 sequences (5558 excluded, 0 skipped).\n",
      "\n",
      "processing Myriapoda.gb ..   converted 2259 / 2328 sequences (69 excluded, 0 skipped).\n",
      "\n",
      "processing Nematomorpha.gb ..   converted 112 / 112 sequences (0 excluded, 0 skipped).\n",
      "\n",
      "processing Neuropterida.gb ..   converted 3049 / 3315 sequences (266 excluded, 0 skipped).\n",
      "\n",
      "processing Odonata.gb ..   converted 5774 / 6568 sequences (794 excluded, 0 skipped).\n",
      "\n",
      "processing Oniscidea.gb ..   converted 1812 / 1888 sequences (76 excluded, 0 skipped).\n",
      "\n",
      "processing Orthopteroidea.gb ..   converted 11982 / 14793 sequences (2811 excluded, 0 skipped).\n",
      "\n",
      "processing Paraneoptera.gb ..   converted 101933 / 107912 sequences (5979 excluded, 0 skipped).\n",
      "\n",
      "processing Plecoptera.gb ..   converted 4072 / 4499 sequences (427 excluded, 0 skipped).\n",
      "\n",
      "processing Siphonaptera.gb ..   converted 234 / 430 sequences (196 excluded, 0 skipped).\n",
      "\n",
      "processing Vertebrata.temp.gb ..   converted 165596 / 217000 sequences (51404 excluded, 0 skipped).\n",
      "\n",
      "processing collembola.gb ..   converted 24115 / 24464 sequences (349 excluded, 0 skipped).\n",
      "\n",
      "processing diplura.gb ..   converted 34 / 48 sequences (14 excluded, 0 skipped).\n",
      "\n",
      "processing positives.gb ..   converted 103 / 111 sequences (8 excluded, 0 skipped).\n",
      "\n",
      "processing protura.gb ..   converted 18 / 24 sequences (6 excluded, 0 skipped).\n",
      "\n",
      "Done - Converted a total of 1797537 records!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "datadir = './'\n",
    "####################\n",
    "gbs = []\n",
    "files = os.listdir(datadir)\n",
    "for f in sorted(files):\n",
    "    if f.endswith('gb'):\n",
    "        gbs.append(f)\n",
    "        \n",
    "gb_to_kraken(db_in_gb=gbs, db_for_kraken='all.kraken.fasta', to_exclude=to_ex, minlength=400, maxlength=1000, v=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter database - only keep sequences that have a reasonable kmer overlap with queries. I use `mirabait` from the MIRA assembler to identify reference sequences that share at least 5 kmers of length 31 with a query. Could be more stringent even, to narrow it down further, but this will do for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get `mirabait` just to do this quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir mira\n",
    "cd mira\n",
    "wget https://sourceforge.net/projects/mira-assembler/files/MIRA/stable/mira_4.0.2_linux-gnu_x86_64_static.tar.bz2\n",
    "tar -xvjf mira_4.0.2_linux-gnu_x86_64_static.tar.bz2\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mira/mira_4.0.2_linux-gnu_x86_64_static/bin/mirabait \\\n",
    "-n 5 -k 31 \\\n",
    "../taxonomic_assignment_full_NT/GLOBAL/global_centroids.fasta all.kraken.fasta \\\n",
    "kraken_k31n5 > mirabait-kraken.log\n",
    "\n",
    "mira/mira_4.0.2_linux-gnu_x86_64_static/bin/mirabait \\\n",
    "-n 5 -k 31 \\\n",
    "../taxonomic_assignment_full_NT/GLOBAL/global_centroids.fasta all.blast.fasta \\\n",
    "blast_k31n5 > mirabait-blast.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mirabait` is not needed any longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf mira/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create blast database (takes about a minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 09/23/2016 23:18:57\n",
      "New DB name:   blast_k31n5\n",
      "New DB title:  blast_k31n5.fasta\n",
      "Sequence type: Nucleotide\n",
      "Keep Linkouts: T\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1319968 sequences in 47.9384 seconds.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "makeblastdb -in blast_k31n5.fasta -dbtype nucl -out blast_k31n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kraken database (takes about 1.5 h using 10 threads and requires about 20G of diskspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-23 14:37:35--  ftp://ftp.ncbi.nih.gov/pub/taxonomy/gi_taxid_nucl.dmp.gz\n",
      "           => ‘gi_taxid_nucl.dmp.gz’\n",
      "Resolving ftp.ncbi.nih.gov (ftp.ncbi.nih.gov)... 130.14.250.13\n",
      "Connecting to ftp.ncbi.nih.gov (ftp.ncbi.nih.gov)|130.14.250.13|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /pub/taxonomy ... done.\n",
      "==> SIZE gi_taxid_nucl.dmp.gz ... 1425122001\n",
      "==> PASV ... done.    ==> RETR gi_taxid_nucl.dmp.gz ... done.\n",
      "Length: 1425122001 (1.3G) (unauthoritative)\n",
      "\n",
      "100%[====================================>] 1,425,122,001 33.7MB/s   in 52s    \n",
      "\n",
      "2016-09-23 14:38:28 (26.2 MB/s) - ‘gi_taxid_nucl.dmp.gz’ saved [1425122001]\n",
      "\n",
      "Downloaded GI to taxon map\n",
      "--2016-09-23 14:38:28--  ftp://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz\n",
      "           => ‘taxdump.tar.gz’\n",
      "Resolving ftp.ncbi.nih.gov (ftp.ncbi.nih.gov)... 130.14.250.13\n",
      "Connecting to ftp.ncbi.nih.gov (ftp.ncbi.nih.gov)|130.14.250.13|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /pub/taxonomy ... done.\n",
      "==> SIZE taxdump.tar.gz ... 37257772\n",
      "==> PASV ... done.    ==> RETR taxdump.tar.gz ... done.\n",
      "Length: 37257772 (36M) (unauthoritative)\n",
      "\n",
      "100%[======================================>] 37,257,772  13.7MB/s   in 2.6s   \n",
      "\n",
      "2016-09-23 14:38:32 (13.7 MB/s) - ‘taxdump.tar.gz’ saved [37257772]\n",
      "\n",
      "Downloaded taxonomy tree data\n",
      "Uncompressed GI to taxon map\n",
      "Uncompressed taxonomy tree data\n"
     ]
    }
   ],
   "source": [
    "!kraken-build --download-taxonomy --db kraken_k31n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added \"kraken_k31n5.fasta\" to library (kraken_k31n5)\r\n"
     ]
    }
   ],
   "source": [
    "!kraken-build --add-to-library kraken_k31n5.fasta --db kraken_k31n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kraken build set to minimize disk writes.\n",
      "Creating k-mer set (step 1 of 6)...\n",
      "Found jellyfish v1.1.11\n",
      "Hash size not specified, using '1001477687'\n",
      "K-mer set created. [27.318s]\n",
      "Skipping step 2, no database reduction requested.\n",
      "Sorting k-mer set (step 3 of 6)...\n",
      "K-mer set sorted. [7m49.986s]\n",
      "Creating GI number to seqID map (step 4 of 6)...\n",
      "GI number to seqID map created. [7.495s]\n",
      "Creating seqID to taxID map (step 5 of 6)...\n",
      "1312753 sequences mapped to taxa. [4.256s]\n",
      "Setting LCAs in database (step 6 of 6)...\n",
      "Finished processing 1319968 sequences\n",
      "Database LCAs set. [1h18m39.563s]\n",
      "Database construction complete. [Total: 1h27m8.646s]\n"
     ]
    }
   ],
   "source": [
    "!kraken-build --build --threads 10 --db kraken_k31n5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
